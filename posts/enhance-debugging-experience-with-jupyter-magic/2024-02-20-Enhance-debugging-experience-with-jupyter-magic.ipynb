{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2bfd35",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "categories:\n",
    "- python\n",
    "- kedro\n",
    "- jupyter\n",
    "description: Jupyter Notebook has been thed default tooling for many. Despite many people trying to get rid of it, it integrates even more deeply with the data ecosystem and it is going to stay. By introducing a Jupyter magig command, the debugging experience has been improve and lower the barrier without learning how to use a debugger. \n",
    "title: Investigation of the Kedro default node names\n",
    "toc: true\n",
    "hide: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a01b4",
   "metadata": {},
   "source": [
    "# Enhancing Debugging experience with Jupyter Magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c66222",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The blog will cover the development of a new feature focused on enhancing the debugging experience for Kedro, a Python framework for building reproducible, maintainable, and modular data pipelines. This feature aims to streamline the debugging process by leveraging Jupyter notebooks and the `inspect` module to quickly restore the context of errors encountered within Kedro pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52447284",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "Debugging complex data pipelines can be challenging, especially when errors occur deep within the pipeline. Traditional debugging methods often involve many manual steps, which can be cumbersome and time-consuming. By introducing a feature that integrates seamlessly with Kedro and Jupyter notebooks, it provides a more interactive debugging experience, we aim to improve the productivity and efficiency of Kedro users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc0360",
   "metadata": {},
   "source": [
    "![jupyter-debug-magic](jupyter-load-node.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c7408",
   "metadata": {},
   "source": [
    "# Requirements & Constraints\n",
    "Functional Requirements:\n",
    "- Seamless integration with Jupyter notebooks - a line magic or cell magic\n",
    "- Automate steps to generate the code to run a Kedro Node.\n",
    "\n",
    "Nice to have:\n",
    "- Able to usein IPython terminal, can be used with debugger.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d1afc",
   "metadata": {},
   "source": [
    "## What's in-scope & out-of-scope?\n",
    "In-scope:\n",
    "- Integration of the feature with Jupyter notebooks.\n",
    "- Mapping of node inputs to function inputs using the inspect module.\n",
    "Out-of-scope:\n",
    "- Two way conversion between Notebook and source code.\n",
    "- Handle nested function definitions - that is a user defined function calling another user defined function which could be arbitary level of depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c5b99",
   "metadata": {},
   "source": [
    "##  Methodology\n",
    "###  Problem Statement\n",
    "The challenge lies in mapping Kedro specific components to generate \n",
    "code that can be explored interactively in notebook to provide a seamless debugging experience. There are few key components that need to be mapped:\n",
    "  - Generate code cell in Notebook\n",
    "  - Loading the \"Datasets\" from a Kedro `DataCatalog`\n",
    "  - Mapping Kedro Node's to Python function.\n",
    "  - A way to execute the code in the notebook\n",
    "  - Import statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e654b2e9",
   "metadata": {},
   "source": [
    "#### Generate Code cell in Notebook\n",
    "Originall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69743d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "731c22ea",
   "metadata": {},
   "source": [
    "#### Kedro Node and Python Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e3060",
   "metadata": {},
   "source": [
    "Kedro Node is a thin wrapper around Python function, with optional metadata such as `name` or `tags` to organise the node in a meaningful way. They are not too important for this particular feature, but useful for filtering pipeline. Kedro has a first party plugin [`kedro-viz`](https://github.com/kedro-org/kedro-viz) that provide an [interactive visualiation](https://demo.kedro.org) of your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8abb993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node(foo, ['data_a', 'data_b'], ['output_data'], 'my_node')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kedro.pipeline import node\n",
    "\n",
    "def foo(a,b):\n",
    "    c = a + b\n",
    "    return c\n",
    "\n",
    "node(foo, inputs=[\"transaction_data\", \"customer_data\"], outputs=[\"output_data\"], name=\"my_node\", tags=\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8f67e",
   "metadata": {},
   "source": [
    "You can see how close the node resembles a typical Python function. The `inputs` and `outputs` refer to the name of a dataset of the Kedro `DataCatalog`. It is basically the key value of the definition of a dataset, which is ususally defined in YAML format.\n",
    "\n",
    "This is an example of the definition of a dataset:\n",
    "```yaml\n",
    "transaction_data:\n",
    "  type: pandas.CSVDataset\n",
    "  filepath: data/01_raw/my_raw_data.csv\n",
    "```\n",
    "\n",
    "`DataCatalog` handles the I/O for Kedro Pipeline, the node only need to declares what data does it needs. The requirements here is that we need to map the inputs to dataset name properly. i.e.\n",
    "- transaction_data -> a\n",
    "- customer_data -> b\n",
    "\n",
    "To run this in a notebook, we need to load the data and call the function.\n",
    "```python\n",
    "a = catalog.load(\"transaction_data\")\n",
    "b = catalog.load(\"customer_data\")\n",
    "\n",
    "foo(a, b)\n",
    "```\n",
    "\n",
    "It's fairly easy to map this particular example, but it becomes tricker if we need to handle `*args`, `**kwargs`, optional arguments and more. This is the syntax that [Kedro Node support](https://docs.kedro.org/en/latest/nodes_and_pipelines/nodes.html#node-definition-syntax).\n",
    "\n",
    "\n",
    "```python\n",
    "def bar(a, b, c, *args, d=None):\n",
    "    return \"bar\"\n",
    "```\n",
    "\n",
    "Consider this function, both node definitions below are valid:\n",
    "- `node(bar, [\"transaction_data\", \"customer_data\", \"sales_data\", \"salary_data\"], [\"output_data\"])`\n",
    "- `node(bar, [\"transaction_data\", \"customer_data\", \"sales_data\"], [\"output_data\"])`\n",
    "\n",
    "The solution of this is using `inspect` module to get the information about the function signature and node, and map it carefully with `inspect.Signature.bind`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190c190",
   "metadata": {},
   "source": [
    "#### Executing the code in a notebook\n",
    "There are 2 variations that we considered:\n",
    "1. Code cell with the function defintion\n",
    "2. Function call\n",
    "\n",
    "Reusing the `foo` function mentioned earlier, with approach 1, we want to flatten it to a code cell in notebook\n",
    "\n",
    "```python\n",
    "def foo(a,b):\n",
    "    c = a + b\n",
    "    return c\n",
    "```\n",
    "\n",
    "Notebook cell:\n",
    "\n",
    "```python\n",
    "a = catalog.load(\"transaction_data\")\n",
    "b = catalog.load(\"customer_data\")\n",
    "\n",
    "c = a + b\n",
    "c\n",
    "```\n",
    "The benefit of this is user can split the cell to inject logic or inspecting variable easily. However, it becomes increasing challenging to retrive the function body only. `inspect` provide method to extract the definition of `foo`, which is a string representation of this:\n",
    "```python\n",
    "def foo(a,b):\n",
    "    c = a + b\n",
    "    return c\n",
    "```\n",
    "\n",
    "In order to make this runnable in a notebook cell, we need to handle a few things:\n",
    "1. Remove the `def` line, which could be multiple lines\n",
    "2. Remove the `return` statement, because it is not valid outside of function.\n",
    "\n",
    "Again, it looks trivial at first, but if we start consideing multiple `return` in a function, it becomes unclear what we should do. In addition, a function could have decorator, which means removing the `def` isn't always desired. At the end, we go with approach 2, which copy the function definition and make a call to it.\n",
    "\n",
    "The notebook cell now look like this:\n",
    "```python\n",
    "a = catalog.load(\"transaction_data\")\n",
    "b = catalog.load(\"customer_data\")\n",
    "\n",
    "def foo(a,b): # Not necessary to copy\n",
    "    c = a + b\n",
    "    return c\n",
    "\n",
    "foo(a, b)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803fd636",
   "metadata": {},
   "source": [
    "#### Import Statement\n",
    "We take a fairly simple approach for this. Using `inspect.getsourcefile(function)`, we can retrive the file that contains the function we desired. After that, we parse the file and retrive all import statements with specific keywords."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
