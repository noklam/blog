{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351c738b",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "categories:\n",
    "- python\n",
    "- kedro\n",
    "- databricks\n",
    "description: In this blog post, I am going to re-implement Kedro in 50 lines of code. I will implement the core components of Kedro such as `ConfigLoader`, `DataCatalog` in a minimalistic way. I will breakdown the process into multiple small steps. In each step I will introduce some code change, and introduce a Kedro concept there. By the end of the blog post, you will have an overview of how Kedro works internally.\n",
    "toc: true\n",
    "hide: false\n",
    "date: '2024-05-31'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90756d",
   "metadata": {},
   "source": [
    "# miniKedro\n",
    "\n",
    "Reimplementing something is one of the best way to learn. Kedro is a data science & data engineer pipeline library at heart. Under the hood, there are few core components such as `ConfigLoader`, `DataCatalog`. You may not notice these classes because the framework allows you to use them implicitly without the need to understand how it actually works.\n",
    "\n",
    "In this blog post, I am going to re-implement Kedro in 50 lines of code. I will start with the classic `spaceflights` tutorial,  By the end of the blog post, you will have an overview of how Kedro works internally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ccbf4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Installation\n",
    "First, clone this repository and install the module and its dependencies in editable mode\n",
    "- `git clone https://github.com/noklam/miniKedro.git`\n",
    "- `pip install -e .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3149ef",
   "metadata": {},
   "source": [
    "The repository is a simplified version of `spaceflights`, confirm that you can actually run the pipeline with this command:\n",
    "`kedro run`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91215a85",
   "metadata": {},
   "source": [
    "## Running the pipeline as a script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0769a4",
   "metadata": {},
   "source": [
    "The goal of this tutorial is replicate the feature of Kedro by slowly introduce new components. We will start with a pure Python script `run.py` that doesn't have any Kedro dependencies.\n",
    "\n",
    "Execute this script with `python run.py`\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Start Pipeline\")\n",
    "    from minikedro.pipelines.data_processing.nodes import (\n",
    "        create_model_input_table,\n",
    "        preprocess_companies,\n",
    "        preprocess_shuttles,\n",
    "    )\n",
    "    from rich.logging import RichHandler\n",
    "    import logging\n",
    "    import pandas as pd\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[RichHandler()],\n",
    "    )\n",
    "    logger = logging.getLogger(\"minikedro\")\n",
    "\n",
    "    companies = pd.read_csv(\"data/01_raw/companies.csv\")\n",
    "    reviews = pd.read_csv(\"data/01_raw/reviews.csv\")\n",
    "    shuttles = pd.read_excel(\"data/01_raw/shuttles.xlsx\")\n",
    "\n",
    "    logger.info(\"Running preprocess_companies\")\n",
    "    processed_companies = preprocess_companies(companies)\n",
    "    logger.info(\"Running preprocess_companies\")\n",
    "    processed_shuttles = preprocess_shuttles(shuttles)\n",
    "    logger.info(\"Running create_model_input_table\")\n",
    "    model_input_table = create_model_input_table(\n",
    "        processed_shuttles, processed_companies, reviews\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ddfa43",
   "metadata": {},
   "source": [
    "Note that we are still importing from `minikedro.pipelines.data_processing.nodes`, this is not cheating because it is just a collections of Python function and they can be used outside of Kedro pipeline. Let's focus on this block of code first:\n",
    "```python\n",
    "    companies = pd.read_csv(\"data/01_raw/companies.csv\")\n",
    "    reviews = pd.read_csv(\"data/01_raw/reviews.csv\")\n",
    "    shuttles = pd.read_excel(\"data/01_raw/shuttles.xlsx\")\n",
    "\n",
    "    logger.info(\"Running preprocess_companies\")\n",
    "    processed_companies = preprocess_companies(companies)\n",
    "    logger.info(\"Running preprocess_companies\")\n",
    "    processed_shuttles = preprocess_shuttles(shuttles)\n",
    "    logger.info(\"Running create_model_input_table\")\n",
    "    model_input_table = create_model_input_table(\n",
    "        processed_shuttles, processed_companies, reviews\n",
    "    )\n",
    "```\n",
    "\n",
    "The code is actually decently structured already, the first 3 lines of code prepare the data, after that there is a few function calls to chain these functions together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998fdc2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Start of the Journey - Step 1: Extract data configuration\n",
    "You can find the scripts and corresponding code in https://github.com/noklam/miniKedro/blob/main/run_v1.py. For step two, simply change the `v1` to `v2`\n",
    "\n",
    "This is the change:\n",
    "![diff v1](images/diff_v1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60dbc4",
   "metadata": {},
   "source": [
    "```python\n",
    "from collections import UserDict\n",
    "\n",
    "\n",
    "class ConfigLoader(UserDict): ...\n",
    "```\n",
    "\n",
    "First, we extract the configuration into a dictionary, and introduce a dictionary-like class called `ConfigLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b78f0",
   "metadata": {},
   "source": [
    "## Step 2 - Replace shared config with templated value\n",
    "After extracting the configuration into `config`, notice that many of the filepath shared a similar pattern. It may make sense to extract that as a variable `_base_folder` so that it can be easily configure to be something else later (i.e. a s3 bucket).\n",
    "\n",
    "![diff_v2](images/diff_v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c62252",
   "metadata": {},
   "source": [
    "`${_base_folder}` is a Jinja like syntax but we are using `OmegaConf` here, which is what Kedro use in its library. The idea is simple, all the value of `${_base_folder}` will be substituted as `data`. Kedro also support a lot more advance configuration feature, which you can find in the [documentation](https://docs.kedro.org/en/stable/configuration/advanced_configuration.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
