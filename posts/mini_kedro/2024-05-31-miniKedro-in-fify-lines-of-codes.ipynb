{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351c738b",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "categories:\n",
    "- python\n",
    "- kedro\n",
    "- databricks\n",
    "description: In this blog post, I am going to re-implement Kedro in 50 lines of code. I will implement the core components of Kedro such as `ConfigLoader`, `DataCatalog` in a minimalistic way. I will breakdown the process into multiple small steps. In each step I will introduce some code change, and introduce a Kedro concept there. By the end of the blog post, you will have an overview of how Kedro works internally.\n",
    "toc: true\n",
    "hide: false\n",
    "date: '2024-05-31'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90756d",
   "metadata": {},
   "source": [
    "# miniKedro - A minimal Kedro implementation \n",
    "\n",
    "Reimplementing something is one of the best way to learn. Kedro is a data science & data engineer pipeline library at heart. Under the hood, there are few core components such as `ConfigLoader`, `DataCatalog`. You may not notice these classes because the framework allows you to use them implicitly without the need to understand how it actually works.\n",
    "\n",
    "In this blog post, I am going to re-implement Kedro in 50 lines of code. I will start with the classic `spaceflights` tutorial,  By the end of the blog post, you will have an overview of how Kedro works internally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ccbf4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Installation\n",
    "First, clone this repository and install the module and its dependencies in editable mode\n",
    "- `git clone https://github.com/noklam/miniKedro.git`\n",
    "- `pip install -e .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3149ef",
   "metadata": {},
   "source": [
    "The repository is a simplified version of `spaceflights`, confirm that you can actually run the pipeline with this command:\n",
    "`kedro run`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91215a85",
   "metadata": {},
   "source": [
    "## Running the pipeline as a script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0769a4",
   "metadata": {},
   "source": [
    "The goal of this tutorial is replicate the feature of Kedro by slowly introduce new components. We will start with a pure Python script `run.py` that doesn't have any Kedro dependencies.\n",
    "\n",
    "Execute this script with `python run.py`\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Start Pipeline\")\n",
    "    from minikedro.pipelines.data_processing.nodes import (\n",
    "        create_model_input_table,\n",
    "        preprocess_companies,\n",
    "        preprocess_shuttles,\n",
    "    )\n",
    "    from rich.logging import RichHandler\n",
    "    import logging\n",
    "    import pandas as pd\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[RichHandler()],\n",
    "    )\n",
    "    logger = logging.getLogger(\"minikedro\")\n",
    "\n",
    "    companies = pd.read_csv(\"data/01_raw/companies.csv\")\n",
    "    reviews = pd.read_csv(\"data/01_raw/reviews.csv\")\n",
    "    shuttles = pd.read_excel(\"data/01_raw/shuttles.xlsx\")\n",
    "\n",
    "    logger.info(\"Running preprocess_companies\")\n",
    "    processed_companies = preprocess_companies(companies)\n",
    "    logger.info(\"Running preprocess_companies\")\n",
    "    processed_shuttles = preprocess_shuttles(shuttles)\n",
    "    logger.info(\"Running create_model_input_table\")\n",
    "    model_input_table = create_model_input_table(\n",
    "        processed_shuttles, processed_companies, reviews\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ddfa43",
   "metadata": {},
   "source": [
    "Note that we are still importing from `minikedro.pipelines.data_processing.nodes`, this is not cheating because it is just a collections of Python function and they can be used outside of Kedro pipeline. Let's focus on this block of code first:\n",
    "```python\n",
    "    companies = pd.read_csv(\"data/01_raw/companies.csv\")\n",
    "    reviews = pd.read_csv(\"data/01_raw/reviews.csv\")\n",
    "    shuttles = pd.read_excel(\"data/01_raw/shuttles.xlsx\")\n",
    "\n",
    "    logger.info(\"Running preprocess_companies\")\n",
    "    processed_companies = preprocess_companies(companies)\n",
    "    logger.info(\"Running preprocess_companies\")\n",
    "    processed_shuttles = preprocess_shuttles(shuttles)\n",
    "    logger.info(\"Running create_model_input_table\")\n",
    "    model_input_table = create_model_input_table(\n",
    "        processed_shuttles, processed_companies, reviews\n",
    "    )\n",
    "```\n",
    "\n",
    "The code is actually decently structured already, the first 3 lines of code prepare the data, after that there is a few function calls to chain these functions together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998fdc2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Start of the Journey - Step 1: Extract data configuration\n",
    "You can find the scripts and corresponding code in https://github.com/noklam/miniKedro/blob/main/run_v1.py. For step two, simply change the `v1` to `v2`\n",
    "\n",
    "This is the change:\n",
    "![diff v1](images/diff_v1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60dbc4",
   "metadata": {},
   "source": [
    "```python\n",
    "from collections import UserDict\n",
    "\n",
    "\n",
    "class ConfigLoader(UserDict): ...\n",
    "```\n",
    "\n",
    "First, we extract the configuration into a dictionary, and introduce a dictionary-like class called `ConfigLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b78f0",
   "metadata": {},
   "source": [
    "## Step 2 - Replace shared config with templated value\n",
    "After extracting the configuration into `config`, notice that many of the filepath shared a similar pattern. It may make sense to extract that as a variable `_base_folder` so that it can be easily configure to be something else later (i.e. a s3 bucket).\n",
    "\n",
    "![diff_v2](images/diff_v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56542b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```python\n",
    "class ConfigLoader(UserDict):\n",
    "    def __init__(self, data: dict):\n",
    "        self.data = OmegaConf.create(data)  # New\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c62252",
   "metadata": {},
   "source": [
    "We introduce `OmegaConf` to support template value like `${_base_folder}`  The idea is simple, all the value of `${_base_folder}` will be substituted as `data`. Kedro also support a lot more advance configuration feature, which you can find in the [documentation](https://docs.kedro.org/en/stable/configuration/advanced_configuration.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b622dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 3 - Introducing `DataCatalog`\n",
    "\n",
    "The next thing that we will do is to introduce the `DataCatalog` class. The `DataCatalog` class and `Dataset`. A `Dataset` is something that can `save` and `load`, and a `DataCatalog` is a container of a collections of `Dataset`(s). Here we leverage the fact that Kedro already has a lot of existing data connectors in `kedro-datasets`.\n",
    "\n",
    "```python\n",
    "class AbstractDataset:\n",
    "    def load(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, data):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class DataCatalog:\n",
    "    def __init__(self, config_catalog: dict):\n",
    "        self.datasets = {}\n",
    "        for dataset_name, config in config_catalog.items():\n",
    "            if isinstance(dataset_name, str) and dataset_name.startswith(\"_\"):\n",
    "                continue  # skip template value\n",
    "            module = config.pop(\"type\")  # pandas.CSVDataset\n",
    "\n",
    "            # CSVDataset(**config) in code\n",
    "            mod, dataset = module.split(\".\")  # pandas, CSVDataset\n",
    "            mod = importlib.import_module(\n",
    "                f\"kedro_datasets.{mod}\"\n",
    "            )  # kedro_datasets.pandas (module)\n",
    "            class_ = getattr(mod, dataset)  # kedro_datasets.pandas.CSVDataset\n",
    "            self.datasets[dataset_name] = class_(**config)\n",
    "\n",
    "    def load(self, dataset_name):\n",
    "        return self.datasets[dataset_name].load()  # CSVDataset.load()\n",
    "```\n",
    "\n",
    "We introduced quite a lot of code here, but most of them are just parsing logic. What's happening here is that the `DataCatalog` takes some configurations, and instantiate `Dataset` class from it. \n",
    "\n",
    "We can now replaced all the `pd` call with the `DataCatalog` instead:\n",
    "![diff_v3](images/diff_v3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa67dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Step 4 - Saving data with `DataCatalog`\n",
    "\n",
    "\n",
    "![diff_v4](images/diff_v4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97084c59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Step 5 - Extracting configuration again, this time for the functions\n",
    "\n",
    "![diff_v5](images/diff_v5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08a4d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 6 - Iterating through the `steps`\n",
    "![diff_v6](images/diff_v6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d4688",
   "metadata": {},
   "source": [
    "## Step 7 - `pipeline` and `node` as a thin wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937e293",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Step 8 - Replace functions with `node` and `pipeline`\n",
    "![diff_v8](images/diff_v8.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c4800",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Step 9 - Extend Kedro with Hooks\n",
    "![diff_v9](images/diff_v9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f61b07",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39fe06db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Conclusion\n",
    "We finish this with [about 50 lines of code](https://github.com/noklam/miniKedro/blob/main/src/minikedro/v9/__init__.py) (ignore newline), and a library that looks very similar to Kedro. We have implemented a few components like:\n",
    "- [`ConfigLoader`](https://docs.kedro.org/en/stable/configuration/index.html)\n",
    "- [`DataCatalog`](https://docs.kedro.org/en/stable/data/index.html)\n",
    "- [`Hook`](https://docs.kedro.org/en/stable/hooks/index.html)\n",
    "- [`pipeline` and `node`](https://docs.kedro.org/en/stable/nodes_and_pipelines/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f8234",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
