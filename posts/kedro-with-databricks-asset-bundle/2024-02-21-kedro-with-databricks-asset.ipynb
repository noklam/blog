{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351c738b",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "categories:\n",
    "- python\n",
    "- kedro\n",
    "- databricks\n",
    "description: Using Kedro with Databricks Assets Bundle\n",
    "toc: true\n",
    "hide: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90756d",
   "metadata": {},
   "source": [
    "# Kedro with Databricks Assets Bundle\n",
    "(Disclaimer: This is not an official documentation).\n",
    "\n",
    "This post describe the process of using Databricks Assets bundle, deploy the notebook to a Databricks workspace and runs the notebook as a Databricks Job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ccbf4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Requirements\n",
    "I test this with the following dependencies:\n",
    "- kedro==0.19.2\n",
    "- databricks-cli==0.214.0 # Installation guide: https://docs.databricks.com/en/dev-tools/cli/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304880e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "First, I create a new kedro project which contains a spark pipeline that are ready to run in databricks with `kedro new -s databricks-iris`. The workflow of using Databricks worksapce to develop Kedro project is documented [here](https://docs.kedro.org/en/stable/deployment/databricks/databricks_notebooks_development_workflow.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a3d84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd25ce2",
   "metadata": {},
   "source": [
    "Next, you need to have the Databricks CLI installed, run this command to create a Databricks Assets Bundle template.\n",
    "\n",
    " `databricks bundle init`, it will prompt you for a few things. For testing purpose, I answer `yes` for all questions. The resulting folder look like this:\n",
    " ![bundle folder structure](bundle-folder.png)\n",
    "\n",
    " This create yet another project template. Both `kedro new` and `databricks bundle init` assume you are creating new project. Since we have a Kedro project already, you don't need the project related files. i.e. `requirements-dev.txt`, `setup.py` and `src/<project_name>`. You can then move everythin from a Kedro project inside the `bundle_example` folder so that they share the same root level. i.e. `pyproject.toml` (create by Kedro) should be in the same level as `databricks.yml`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28303432",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "`databricks bundle deploy -t dev`\n",
    "Error: terraform apply: exit status 1\n",
    "\n",
    "Error: cannot create job: default auth: cannot configure default credentials, please check https://docs.databricks.com/en/dev-tools/auth.html#databricks-client-unified-authentication to configure credentials for your preferred authentication method. Config: host=https://adb-4127266075722018.18.azuredatabricks.net. Env: DATABRICKS_HOST\n",
    "\n",
    "  with databricks_job.my_project_job,\n",
    "  on bundle.tf.json line 77, in resource.databricks_job.my_project_job:\n",
    "  77:       }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f827c791",
   "metadata": {},
   "source": [
    "I try to submit a job immediately after creating the bundles, the error suggests that I need to create a developer token to submit job to Databricks locally. Go to Databricks workspace -> User Settings -> Developer -> Generate New\n",
    "\n",
    "Run in terminal:\n",
    "`export DATABRICKS_TOKEN=<your-token>`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796b9544",
   "metadata": {},
   "source": [
    "After this, I run `databricks bundle deploy -t dev` again and I see this in my workspace.\n",
    "\n",
    "![workspace-budnle](workspace-bundle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a507c6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If you name your bundle `my_project`, you should see a `my_project_job.yml`. You will need to update the `tasks` and the `notebook_path` to the targeted notebook.\n",
    "`databricks bundle run -t dev my_project_job`\n",
    "\n",
    "For example:\n",
    "```yaml\n",
    "      tasks:\n",
    "        - task_key: notebook_task\n",
    "          job_cluster_key: job_cluster\n",
    "          notebook_task:\n",
    "            notebook_path: ../src/notebook.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bccabdf",
   "metadata": {},
   "source": [
    "After this, I can submit a job and see this on Databricks. Unfortunately I cannot get it running because I have permission issue to create a Databricks Job, but I can see the job request on the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0cf861",
   "metadata": {},
   "source": [
    "Appendix:\n",
    "### The databricks asset bundle use `entrypoints` for deployment.\n",
    "```python\n",
    "   entry_points={\n",
    "        \"packages\": [\n",
    "            \"main=my_project.main:main\"\n",
    "        ]\n",
    "    },\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef67a56",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
