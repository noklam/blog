{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351c738b",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "categories:\n",
    "- python\n",
    "- kedro\n",
    "- databricks\n",
    "description: Kedro Pipeline provides options allow you to slice and compose pipelines effortlessly\n",
    "toc: true\n",
    "hide: false\n",
    "date: '2024-03-06'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b41ed3",
   "metadata": {},
   "source": [
    "# Kedro Pipeline (1) - Slicing Pipeline Effortlessly 🍕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af288682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedro.pipeline import pipeline, node\n",
    "from kedro.pipeline.node import Node\n",
    "def foo():\n",
    "   return \"bar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a67cc",
   "metadata": {},
   "source": [
    "# Kedro Node and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bcbedf",
   "metadata": {},
   "source": [
    "Kedro introduces the concepts of Nodes and Pipelines. A basic understanding of these concepts is assumed. However, if you're unfamiliar, you can refer to the Nodes and Pipelines documentation for more details.\n",
    "\n",
    "In essence, a Kedro Node acts as a thin wrapper around a Python function, specifying its inputs and outputs. On the other hand, a Pipeline is essentially a collection of Nodes that are strung together. When a pipeline is executed, Kedro resolves the dependencies between nodes to determine the correct order of execution.\n",
    "\n",
    "While Kedro is primarily designed for data and machine learning applications, it can be utilized for executing any sequential tasks, including parallel processing if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e41e36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Node(foo, None, 'output_a', None), Pipeline([]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_a = node(func=foo, inputs=None, outputs=\"output_a\")\n",
    "first_pipeline = pipeline([])\n",
    "node_a, first_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93641b53",
   "metadata": {},
   "source": [
    "`pipeline` is a factory method that expects a list of `Node` and produce the `Pipeline` object. In this example, we have an empty `Pipeline`. Below is another valid example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "858abcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(foo, None, 'output_a', None)\n",
       "])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline([node_a])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2074581",
   "metadata": {},
   "source": [
    "## Node Uniqueness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eedde9",
   "metadata": {},
   "source": [
    "The pipeline in Kedro automatically validates Node instances. Specifically, nodes cannot produce the same output (though they can share the same input), and there cannot be duplicate nodes within the pipeline. This validation is crucial to ensure that the pipeline forms an executable Directed Acyclic Graph (DAG), allowing for proper execution and preventing any cyclic dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c2e5065",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pipeline nodes must have unique names. The following node names appear more than once:\n\nFree nodes:\n  - foo(None) -> [output_a]\n\nYou can name your nodes using the last argument of 'node()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_a\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/blog/lib/python3.10/site-packages/kedro/pipeline/modular_pipeline.py:210\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(pipe, inputs, outputs, parameters, tags, namespace)\u001b[0m\n\u001b[1;32m    208\u001b[0m     pipe \u001b[38;5;241m=\u001b[39m Pipeline([pipe], tags\u001b[38;5;241m=\u001b[39mtags)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     pipe \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m([inputs, outputs, parameters, namespace]):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pipe\n",
      "File \u001b[0;32m~/miniconda3/envs/blog/lib/python3.10/site-packages/kedro/pipeline/pipeline.py:138\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, nodes, tags)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is None. It must be an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterable of nodes and/or pipelines instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m     )\n\u001b[1;32m    137\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes)  \u001b[38;5;66;03m# in case it's a generator\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m \u001b[43m_validate_duplicate_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    141\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m    142\u001b[0m         [[n] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, Node) \u001b[38;5;28;01melse\u001b[39;00m n\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    145\u001b[0m _validate_transcoded_inputs_outputs(nodes)\n",
      "File \u001b[0;32m~/miniconda3/envs/blog/lib/python3.10/site-packages/kedro/pipeline/pipeline.py:832\u001b[0m, in \u001b[0;36m_validate_duplicate_nodes\u001b[0;34m(nodes_or_pipes)\u001b[0m\n\u001b[1;32m    829\u001b[0m     nodes_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(names))\n\u001b[1;32m    830\u001b[0m     duplicates_info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipe_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnodes_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 832\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline nodes must have unique names. The following node names \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappear more than once:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mduplicates_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mYou can name your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes using the last argument of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    836\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Pipeline nodes must have unique names. The following node names appear more than once:\n\nFree nodes:\n  - foo(None) -> [output_a]\n\nYou can name your nodes using the last argument of 'node()'."
     ]
    }
   ],
   "source": [
    "pipeline([node_a, node_a])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb982c57",
   "metadata": {},
   "source": [
    "On the other hand, `Node` are considered equal if they have the same `inputs`, `outputs `and `function` (and node name if provided, it is an optional argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03d36123",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_b = node(foo, inputs=None, outputs=\"output_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba0b3ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_b == node_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a606b5",
   "metadata": {},
   "source": [
    "Internally, it is comparing the `name` attribute, which is a combination of namespace, function name, inputs and outputs. This is not important to most Kedro users and are only used by Kedro internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9704c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo(None) -> [output_a]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_a.name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d1cd315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Return str(self).\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0m_set_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"[{','.join(xset)}]\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mout_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0min_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"{self._func_name}({in_str}) -> {out_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/blog/lib/python3.10/site-packages/kedro/pipeline/node.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "Node.__str__??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbcffd",
   "metadata": {},
   "source": [
    "## Pipeline Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feae4d9",
   "metadata": {},
   "source": [
    "The closest analogy to `Pipeline` is the Python `set`. They share simliary characteristics:\n",
    "- The elements cannot be repeated.\n",
    "- Pipelines can be added or subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "706d186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(foo, None, 'output_a', None)\n",
       "])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline([node_a]) + pipeline([node_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "827b6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = node(foo, None, \"a\")\n",
    "b = node(foo, None, \"b\")\n",
    "c = node(foo, None, \"c\")\n",
    "d = node(foo, None, \"d\")\n",
    "\n",
    "original_set = set([\"a\",\"b\",\"c\"])\n",
    "original_pipeline = pipeline([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b290305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(foo, None, 'a', None),\n",
       "Node(foo, None, 'b', None)\n",
       "])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline([a]) + pipeline([b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "456c8188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(foo, None, 'a', None)\n",
       "])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline([a, b]) - pipeline([b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0cb3146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(foo, None, 'b', None)\n",
       "])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline([a, b]) - pipeline([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd39f9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c', 'd'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_set| set([\"b\",\"c\",\"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9527989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(foo, None, 'a', None),\n",
       "Node(foo, None, 'b', None),\n",
       "Node(foo, None, 'c', None),\n",
       "Node(foo, None, 'd', None)\n",
       "])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline([a,b,c])| pipeline([b,c,d]) # nodes in both pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87d16d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'c'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_set & set([\"b\",\"c\",\"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19ad21db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(foo, None, 'b', None),\n",
       "Node(foo, None, 'c', None)\n",
       "])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline([a,b,c]) & pipeline([b,c,d]) # only nodes that exist in both pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e859f3",
   "metadata": {},
   "source": [
    "Pipeline arithmetic is more useful for pipeline registration i.e. `pipeline_registry.py`. For example, you can combine your development pipeline and inference pipeline in different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b649685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_node(name):\n",
    "    return node(foo, inputs=None, outputs=name, name=name)\n",
    "\n",
    "# For simplicaition, let's assume each pipeline is just one single node.\n",
    "spark_pipeline = pipeline([fake_node(\"spark\")])\n",
    "feature_engineering = pipeline([fake_node(\"feature_engineering\")])\n",
    "model_training = pipeline([fake_node(\"model_pipeline\")])\n",
    "inference = pipeline([fake_node(\"inference\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3f3c2",
   "metadata": {},
   "source": [
    "With 4 base pipelines, you can combined them in different ways. For example you want a e2e pipeline which add all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f01d938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e = spark_pipeline + feature_engineering + model_training + inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da7ba8",
   "metadata": {},
   "source": [
    "You can also have a `local` pipeline that skip only the `spark` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2065c245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(foo, None, 'feature_engineering', 'feature_engineering'),\n",
       "Node(foo, None, 'inference', 'inference'),\n",
       "Node(foo, None, 'model_pipeline', 'model_pipeline')\n",
       "])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local = e2e - spark_pipeline\n",
    "local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9ba8e",
   "metadata": {},
   "source": [
    "## Advance Pipeline Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36829b8",
   "metadata": {},
   "source": [
    "Kedro provides an [interaction visualisation](https://demo.kedro.org/) that you can play around with, for this post I am gonna stick with the demo project and explains concepts about Pipeline and how you can slice pipeline and compose them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d434aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext kedro.ipython\n",
    "%cd /Users/Nok_Lam_Chan/dev/kedro-viz/demo-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f20f5a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/07/24 14:02:54] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reached after_catalog_created hook                                        <a href=\"file:///Users/Nok_Lam_Chan/dev/kedro/features/steps/test_plugin/plugin.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plugin.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Nok_Lam_Chan/dev/kedro/features/steps/test_plugin/plugin.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/07/24 14:02:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reached after_catalog_created hook                                        \u001b]8;id=125820;file:///Users/Nok_Lam_Chan/dev/kedro/features/steps/test_plugin/plugin.py\u001b\\\u001b[2mplugin.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=528818;file:///Users/Nok_Lam_Chan/dev/kedro/features/steps/test_plugin/plugin.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project modular-spaceflights                                     <a href=\"file:///Users/Nok_Lam_Chan/dev/kedro/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Nok_Lam_Chan/dev/kedro/kedro/ipython/__init__.py#134\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project modular-spaceflights                                     \u001b]8;id=999443;file:///Users/Nok_Lam_Chan/dev/kedro/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=270713;file:///Users/Nok_Lam_Chan/dev/kedro/kedro/ipython/__init__.py#134\u001b\\\u001b[2m134\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Defined global variable <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'session'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'catalog'</span> and            <a href=\"file:///Users/Nok_Lam_Chan/dev/kedro/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Nok_Lam_Chan/dev/kedro/kedro/ipython/__init__.py#135\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'pipelines'</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Defined global variable \u001b[32m'context'\u001b[0m, \u001b[32m'session'\u001b[0m, \u001b[32m'catalog'\u001b[0m and            \u001b]8;id=482871;file:///Users/Nok_Lam_Chan/dev/kedro/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=934093;file:///Users/Nok_Lam_Chan/dev/kedro/kedro/ipython/__init__.py#135\u001b\\\u001b[2m135\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'pipelines'\u001b[0m                                                            \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_kedro /Users/Nok_Lam_Chan/dev/kedro-viz/demo-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf92af",
   "metadata": {},
   "source": [
    "By using the `reload_kedro` inside a notebook, you can access the project `pipelines` object. Let's say I want to filter out the [highlighted pipeline](https://demo.kedro.org/?pipeline_id=__default__&selected_id=04ba733a) like this (click on the \"Create Derived Features\"):\n",
    "![Select a node on kedro-viz](kedro-viz-selection.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754b8e4",
   "metadata": {},
   "source": [
    "To filter this with the `Pipeline` API, you need two options. `from-nodes`(downstream) and `to-nodes` (upstream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0db77f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mdict_keys\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'__default__'\u001b[0m, \u001b[32m'Data ingestion'\u001b[0m, \u001b[32m'Modelling stage'\u001b[0m, \u001b[32m'Feature engineering'\u001b[0m, \u001b[32m'Reporting stage'\u001b[0m, \u001b[32m'Pre-modelling'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55071abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPipeline\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mapply_types_to_companies, \u001b[32m'companies'\u001b[0m, \u001b[32m'ingestion.int_typed_companies'\u001b[0m, \u001b[32m'apply_types_to_companies'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mapply_types_to_reviews, \u001b[1m[\u001b[0m\u001b[32m'reviews'\u001b[0m, \u001b[32m'params:ingestion.typing.reviews.columns_as_floats'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'ingestion.int_typed_reviews'\u001b[0m, \u001b[32m'apply_types_to_reviews'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mapply_types_to_shuttles, \u001b[32m'shuttles'\u001b[0m, \u001b[32m'ingestion.int_typed_shuttles@pandas1'\u001b[0m, \u001b[32m'apply_types_to_shuttles'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0maggregate_company_data, \u001b[32m'ingestion.int_typed_companies'\u001b[0m, \u001b[32m'ingestion.prm_agg_companies'\u001b[0m, \u001b[32m'company_agg'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mcombine_shuttle_level_information, \u001b[1m{\u001b[0m\u001b[32m'shuttles'\u001b[0m: \u001b[32m'ingestion.int_typed_shuttles@pandas2'\u001b[0m, \u001b[32m'reviews'\u001b[0m: \u001b[32m'ingestion.int_typed_reviews'\u001b[0m, \u001b[32m'companies'\u001b[0m: \u001b[32m'ingestion.prm_agg_companies'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'prm_shuttle_company_reviews'\u001b[0m, \u001b[32m'prm_spine_table'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'combine_step'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mcreate_derived_features, \u001b[1m[\u001b[0m\u001b[32m'prm_spine_table'\u001b[0m, \u001b[32m'prm_shuttle_company_reviews'\u001b[0m, \u001b[32m'params:feature_engineering.feature.derived'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'feature_engineering.feat_derived_features'\u001b[0m, \u001b[32m'create_derived_features'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mcreate_feature_importance, \u001b[32m'prm_spine_table'\u001b[0m, \u001b[32m'feature_importance_output'\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mcreate_static_features, \u001b[1m[\u001b[0m\u001b[32m'prm_shuttle_company_reviews'\u001b[0m, \u001b[32m'params:feature_engineering.feature.static'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'feature_engineering.feat_static_features'\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mlambda\u001b[0m\u001b[1m>\u001b[0m, \u001b[32m'prm_spine_table'\u001b[0m, \u001b[32m'ingestion.prm_spine_table_clone'\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mcreate_matplotlib_chart, \u001b[32m'prm_shuttle_company_reviews'\u001b[0m, \u001b[32m'reporting.confusion_matrix'\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fadb85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPipeline\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mcreate_derived_features, \u001b[1m[\u001b[0m\u001b[32m'prm_spine_table'\u001b[0m, \u001b[32m'prm_shuttle_company_reviews'\u001b[0m, \u001b[32m'params:feature_engineering.feature.derived'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'feature_engineering.feat_derived_features'\u001b[0m, \u001b[32m'create_derived_features'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_name = \"feature_engineering.create_derived_features\" # make s|apipeline\n",
    "full_pipeline.filter(from_nodes=[node_name], to_nodes=[node_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046db168",
   "metadata": {},
   "source": [
    "This only select one node because by default the `filter` method apply both method as an `and` condition. So we need to apply the `filter` method separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f689ff98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPipeline\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mapply_types_to_companies, \u001b[32m'companies'\u001b[0m, \u001b[32m'ingestion.int_typed_companies'\u001b[0m, \u001b[32m'apply_types_to_companies'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mapply_types_to_reviews, \u001b[1m[\u001b[0m\u001b[32m'reviews'\u001b[0m, \u001b[32m'params:ingestion.typing.reviews.columns_as_floats'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'ingestion.int_typed_reviews'\u001b[0m, \u001b[32m'apply_types_to_reviews'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mapply_types_to_shuttles, \u001b[32m'shuttles'\u001b[0m, \u001b[32m'ingestion.int_typed_shuttles@pandas1'\u001b[0m, \u001b[32m'apply_types_to_shuttles'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0maggregate_company_data, \u001b[32m'ingestion.int_typed_companies'\u001b[0m, \u001b[32m'ingestion.prm_agg_companies'\u001b[0m, \u001b[32m'company_agg'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mcombine_shuttle_level_information, \u001b[1m{\u001b[0m\u001b[32m'shuttles'\u001b[0m: \u001b[32m'ingestion.int_typed_shuttles@pandas2'\u001b[0m, \u001b[32m'reviews'\u001b[0m: \u001b[32m'ingestion.int_typed_reviews'\u001b[0m, \u001b[32m'companies'\u001b[0m: \u001b[32m'ingestion.prm_agg_companies'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'prm_shuttle_company_reviews'\u001b[0m, \u001b[32m'prm_spine_table'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'combine_step'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mcreate_derived_features, \u001b[1m[\u001b[0m\u001b[32m'prm_spine_table'\u001b[0m, \u001b[32m'prm_shuttle_company_reviews'\u001b[0m, \u001b[32m'params:feature_engineering.feature.derived'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'feature_engineering.feat_derived_features'\u001b[0m, \u001b[32m'create_derived_features'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mjoiner, \u001b[1m[\u001b[0m\u001b[32m'prm_spine_table'\u001b[0m, \u001b[32m'feature_engineering.feat_static_features'\u001b[0m, \u001b[32m'feature_engineering.feat_derived_features'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'model_input_table'\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0msplit_data, \u001b[1m[\u001b[0m\u001b[32m'model_input_table'\u001b[0m, \u001b[32m'params:split_options'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'X_train'\u001b[0m, \u001b[32m'X_test'\u001b[0m, \u001b[32m'y_train'\u001b[0m, \u001b[32m'y_test'\u001b[0m\u001b[1m]\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mtrain_model, \u001b[1m[\u001b[0m\u001b[32m'X_train'\u001b[0m, \u001b[32m'y_train'\u001b[0m, \u001b[32m'params:train_evaluation.model_options.linear_regression'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'train_evaluation.linear_regression.regressor'\u001b[0m, \u001b[32m'train_evaluation.linear_regression.experiment_params'\u001b[0m\u001b[1m]\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1;35mNode\u001b[0m\u001b[1m(\u001b[0mtrain_model, \u001b[1m[\u001b[0m\u001b[32m'X_train'\u001b[0m, \u001b[32m'y_train'\u001b[0m, \u001b[32m'params:train_evaluation.model_options.random_forest'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'train_evaluation.random_forest.regressor'\u001b[0m, \u001b[32m'train_evaluation.random_forest.experiment_params'\u001b[0m\u001b[1m]\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.filter(from_nodes=[node_name]) | full_pipeline.filter(to_nodes=[node_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d811e6",
   "metadata": {},
   "source": [
    "Now we get the correct filtered pipeline as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0525370",
   "metadata": {},
   "source": [
    "## More notes\n",
    "### The `Pipeline.filter` support `or` operator\n",
    "While the current filter supports many options, there may be some value to wrap around the Pipeline API to support things like `or`. This is only possible if you use the Python API directly but not CLI (with the example above). maybe something similar to the [Graph Operators in dbt](https://docs.getdbt.com/reference/node-selection/graph-operators).\n",
    "\n",
    "e.g. \n",
    "```\n",
    "kedro run --select \"my_model+\"         # select my_model and all children\n",
    "kedro run --select \"+my_model\"         # select my_model and all parents\n",
    "kedro run --select \"+my_model+\"        # select my_model, and all of its parents and children\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a392afc",
   "metadata": {},
   "source": [
    "### Selecting or slicing multiple pipeline with `kedro run`\n",
    "Since Pipeline API support arithmetic, it would be quite straight forward to support things like `kedro run --pipeline a+b` or `kedro run --pipeline a-b`. Let's have a look what's options are available for the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802c6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: kedro run [OPTIONS]\n",
      "\n",
      "  Run the pipeline.\n",
      "\n",
      "Options:\n",
      "  --from-inputs TEXT         A list of dataset names which should be used as a\n",
      "                             starting point.\n",
      "  --to-outputs TEXT          A list of dataset names which should be used as\n",
      "                             an end point.\n",
      "  --from-nodes TEXT          A list of node names which should be used as a\n",
      "                             starting point.\n",
      "  --to-nodes TEXT            A list of node names which should be used as an\n",
      "                             end point.\n",
      "  -n, --nodes TEXT           Run only nodes with specified names.\n",
      "  -r, --runner TEXT          Specify a runner that you want to run the\n",
      "                             pipeline with. Available runners:\n",
      "                             'SequentialRunner', 'ParallelRunner' and\n",
      "                             'ThreadRunner'.\n",
      "  --async                    Load and save node inputs and outputs\n",
      "                             asynchronously with threads. If not specified,\n",
      "                             load and save datasets synchronously.\n",
      "  -e, --env TEXT             Kedro configuration environment name. Defaults to\n",
      "                             `local`.\n",
      "  -t, --tags TEXT            Construct the pipeline using only nodes which\n",
      "                             have this tag attached. Option can be used\n",
      "                             multiple times, what results in a pipeline\n",
      "                             constructed from nodes having any of those tags.\n",
      "  -lv, --load-versions TEXT  Specify a particular dataset version (timestamp)\n",
      "                             for loading.\n",
      "  -p, --pipeline TEXT        Name of the registered pipeline to run. If not\n",
      "                             set, the '__default__' pipeline is run.\n",
      "  -ns, --namespace TEXT      Name of the node namespace to run.\n",
      "  -c, --config FILE          Specify a YAML configuration file to load the run\n",
      "                             command arguments from. If command line arguments\n",
      "                             are provided, they will override the loaded ones.\n",
      "  --conf-source PATH         Path of a directory where project configuration\n",
      "                             is stored.\n",
      "  --params TEXT              Specify extra parameters that you want to pass to\n",
      "                             the context initialiser. Items must be separated\n",
      "                             by comma, keys - by colon or equals sign,\n",
      "                             example: param1=value1,param2=value2. Each\n",
      "                             parameter is split by the first comma, so\n",
      "                             parameter values are allowed to contain colons,\n",
      "                             parameter keys are not. To pass a nested\n",
      "                             dictionary as parameter, separate keys by '.',\n",
      "                             example: param_group.param1:value1.\n",
      "  -h, --help                 Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!kedro run --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3cd02",
   "metadata": {},
   "source": [
    "This is what happen when you do `kedro run -p training -t model_a`, it's a two steps flitering:\n",
    "1. Apply the `-p` pipeline name to select a key from the pipeline dictionary, it's just `pipelines[pipeline_name]`, note this mean you can only select ONE pipeline at a time.\n",
    "2. The pipeline is then further filtered with `Pipeline.filter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dd3cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfrom_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mto_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnode_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfrom_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mto_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnode_namespace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# noqa: PLR0913\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfrom_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mto_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnode_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfrom_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mto_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnode_namespace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Creates a new ``Pipeline`` object with the nodes that meet all of the\u001b[0m\n",
      "\u001b[0;34m        specified filtering conditions.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        The new pipeline object is the intersection of pipelines that meet each\u001b[0m\n",
      "\u001b[0;34m        filtering condition. This is distinct from chaining multiple filters together.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m            tags: A list of node tags which should be used to lookup\u001b[0m\n",
      "\u001b[0;34m                the nodes of the new ``Pipeline``.\u001b[0m\n",
      "\u001b[0;34m            from_nodes: A list of node names which should be used as a\u001b[0m\n",
      "\u001b[0;34m                starting point of the new ``Pipeline``.\u001b[0m\n",
      "\u001b[0;34m            to_nodes:  A list of node names which should be used as an\u001b[0m\n",
      "\u001b[0;34m                end point of the new ``Pipeline``.\u001b[0m\n",
      "\u001b[0;34m            node_names: A list of node names which should be selected for the\u001b[0m\n",
      "\u001b[0;34m                new ``Pipeline``.\u001b[0m\n",
      "\u001b[0;34m            from_inputs: A list of inputs which should be used as a starting point\u001b[0m\n",
      "\u001b[0;34m                of the new ``Pipeline``\u001b[0m\n",
      "\u001b[0;34m            to_outputs: A list of outputs which should be the final outputs of\u001b[0m\n",
      "\u001b[0;34m                the new ``Pipeline``.\u001b[0m\n",
      "\u001b[0;34m            node_namespace: One node namespace which should be used to select\u001b[0m\n",
      "\u001b[0;34m                nodes in the new ``Pipeline``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns:\u001b[0m\n",
      "\u001b[0;34m            A new ``Pipeline`` object with nodes that meet all of the specified\u001b[0m\n",
      "\u001b[0;34m                filtering conditions.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Raises:\u001b[0m\n",
      "\u001b[0;34m            ValueError: The filtered ``Pipeline`` has no nodes.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Example:\u001b[0m\n",
      "\u001b[0;34m        ::\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            >>> pipeline = Pipeline(\u001b[0m\n",
      "\u001b[0;34m            >>>     [\u001b[0m\n",
      "\u001b[0;34m            >>>         node(func, \"A\", \"B\", name=\"node1\"),\u001b[0m\n",
      "\u001b[0;34m            >>>         node(func, \"B\", \"C\", name=\"node2\"),\u001b[0m\n",
      "\u001b[0;34m            >>>         node(func, \"C\", \"D\", name=\"node3\"),\u001b[0m\n",
      "\u001b[0;34m            >>>     ]\u001b[0m\n",
      "\u001b[0;34m            >>> )\u001b[0m\n",
      "\u001b[0;34m            >>> pipeline.filter(node_names=[\"node1\", \"node3\"], from_inputs=[\"A\"])\u001b[0m\n",
      "\u001b[0;34m            >>> # Gives a new pipeline object containing node1 and node3.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Use [node_namespace] so only_nodes_with_namespace can follow the same\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# *filter_args pattern as the other filtering methods, which all take iterables.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnode_namespace_iterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnode_namespace\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode_namespace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfilter_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monly_nodes_with_tags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfrom_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monly_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfrom_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monly_nodes_with_namespace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode_namespace_iterable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msubset_pipelines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfilter_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mfilter_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilter_methods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mfilter_args\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Intersect all the pipelines subsets. We apply each filter to the original\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# pipeline object (self) rather than incrementally chaining filter methods\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# together. Hence the order of filtering does not affect the outcome, and the\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# resultant pipeline is unambiguously defined.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# If this were not the case then, for example,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# pipeline.filter(node_names=[\"node1\", \"node3\"], from_inputs=[\"A\"])\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# would give different outcomes depending on the order of filter methods:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# only_nodes and then from_inputs would give node1, while only_nodes and then\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# from_inputs would give node1 and node3.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfiltered_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0msubset_pipeline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset_pipelines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfiltered_pipeline\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0msubset_pipeline\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Pipeline contains no nodes after applying all provided filters\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/dev/kedro/kedro/pipeline/pipeline.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "from kedro.pipeline.pipeline import Pipeline\n",
    "Pipeline.filter??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bcd924",
   "metadata": {},
   "source": [
    "This means that, if you have tags applied across multiple pipeline, you cannot filter it by tag, unless you apply the filter in the largest pipeline that contains all nodes. What if we can support things like:\n",
    "`kedro run -p feature+training -t model_a`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054939d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
